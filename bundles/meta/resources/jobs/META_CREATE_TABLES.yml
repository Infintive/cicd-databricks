resources:
  jobs:
    META_CREATE_TABLES:
      name: "META_CREATE_TABLES"
      max_concurrent_runs: 1
      parameters:
        - name: env
          default: ${var.CICD_ENV}
        - name: root_path
          default: ${workspace.root_path}
      tasks:

        - task_key: 0_Config_Database_And_Tables_Creation
          notebook_task:
            notebook_path: ../../../../databricks_notebooks/CONFIG/0_Config_Database_And_Tables_Creation.py
            source: WORKSPACE
          job_cluster_key: META_CREATE_TABLES_CLUSTER

        - task_key: copy_csv_to_volume
          notebook_task:
            notebook_path: ../../../../databricks_notebooks/CONFIG/copy_csv_to_volume.py
            source: WORKSPACE
          job_cluster_key: META_CREATE_TABLES_CLUSTER
          depends_on:
            - task_key: "0_Config_Database_And_Tables_Creation"

        - task_key: 1_Config_tables_Data_Load
          notebook_task:
            notebook_path: ../../../../databricks_notebooks/CONFIG/1_Config_tables_Data_Load.py
            source: WORKSPACE
          job_cluster_key: META_CREATE_TABLES_CLUSTER
          depends_on:
            - task_key: "copy_csv_to_volume"
            
      ## Job cluster defintion
      job_clusters:
        - job_cluster_key: META_CREATE_TABLES_CLUSTER
          new_cluster:
            spark_version: 16.4.x-scala2.12
            azure_attributes:
              first_on_demand: 1
              availability: SPOT_WITH_FALLBACK_AZURE
              spot_bid_max_price: 100
            node_type_id: Standard_D4ds_v5
            enable_elastic_disk: true
            policy_id: ${var.JC_POLICY_ID}
            data_security_mode: SINGLE_USER
            single_user_name: ${workspace.current_user.userName}
            runtime_engine: PHOTON
            autoscale:
              min_workers: 1
              max_workers: 1
      queue:
        enabled: true
      lifecycle:
        prevent_destroy: false
      tags:
        deploy_type: CI/CD
        bundle: META
        type: SETUP